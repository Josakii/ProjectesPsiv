{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcions_finals.matricula_to_digits_2 import matricula_to_digits\n",
    "from funcions_finals.digits_to_predicts_3 import predict_digits, CNNModel_a, CNNModel_n\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FALTA:\n",
    "\n",
    "## acabar YOLO:\n",
    "### - EMPALMAR MODEL YOLO\n",
    "### - VALIDAR YOLO (1)\n",
    "\n",
    "## detectar errors img classif\n",
    "### - CREAR METRICA VALID\n",
    "### - VALIDAR IMG CLASSIF (2)\n",
    "### - CROSS VALIDATION\n",
    "### - TEST HIP FINAL\n",
    "\n",
    "## solució errors\n",
    "### - PROVAR NOUS MODELS\n",
    "### - CANVIAR DISTRIBUCIÓ DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMATGE -> MATRICULA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2024-10-5 Python-3.9.7 torch-2.4.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "c:\\Users\\mirvi\\Desktop\\mii\\UAB\\4.1\\PSIV2\\detect mateicules\\r1\\yolov5\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    }
   ],
   "source": [
    "from funcions_finals.image_to_matricula_1 import crop_matricula\n",
    "\n",
    "image_path = 'img_exemple\\mat_es2.jpg'\n",
    "\n",
    "cropped_m = crop_matricula(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MATRICULA -> DIGITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input: cv2 image\n",
    "- output: list dels digits cv2 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 23 16 31\n",
      "40 21 15 30\n",
      "57 18 14 31\n",
      "73 16 15 30\n",
      "97 12 14 31\n",
      "113 10 13 30\n",
      "128 7 14 30\n",
      "(31, 16)\n",
      "(30, 15)\n",
      "(31, 14)\n",
      "(30, 15)\n",
      "(31, 14)\n",
      "(30, 13)\n",
      "(30, 14)\n"
     ]
    }
   ],
   "source": [
    "digits = matricula_to_digits(cropped_m)\n",
    "\n",
    "num_digits = digits[0:4]\n",
    "alfa_digits = digits[4:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DIGITS -> PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel_n(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=5120, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar los modelos\n",
    "model_alfa = CNNModel_a()\n",
    "model_num = CNNModel_n()\n",
    "\n",
    "# Cargar los estados de los modelos\n",
    "model_alfa.load_state_dict(torch.load(\"models/CNN1-alfa.pt\"))\n",
    "model_num.load_state_dict(torch.load(\"models/CNN1-numeros.pt\"))\n",
    "\n",
    "# Cambiar a modo de evaluación\n",
    "model_alfa.eval()\n",
    "model_num.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preds, alfa_preds = predict_digits(num_digits, alfa_digits,model_num,model_alfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 5, 8] ['K', 'C', 'J']\n"
     ]
    }
   ],
   "source": [
    "# show original image\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(cropped_m, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# show predicted digits\n",
    "print(num_preds, alfa_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCIO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2024-10-5 Python-3.9.7 torch-2.4.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "c:\\Users\\mirvi\\Desktop\\mii\\UAB\\4.1\\PSIV2\\detect mateicules\\r1\\yolov5\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 23 16 31\n",
      "40 21 15 30\n",
      "57 18 14 31\n",
      "73 16 15 30\n",
      "97 12 14 31\n",
      "113 10 13 30\n",
      "128 7 14 30\n",
      "(31, 16)\n",
      "(30, 15)\n",
      "(31, 14)\n",
      "(30, 15)\n",
      "(31, 14)\n",
      "(30, 13)\n",
      "(30, 14)\n",
      "[0, 9, 5, 8] ['K', 'C', 'J']\n"
     ]
    }
   ],
   "source": [
    "from funcions_finals.detector_matricula import detect_matricula\n",
    "\n",
    "image_path = 'img_exemple\\mat_es2.jpg'\n",
    "\n",
    "num_preds, alfa_preds = detect_matricula(image_path)\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "print(num_preds, alfa_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
